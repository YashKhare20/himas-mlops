steps:
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
      - '-t'
      - 'gcr.io/$PROJECT_ID/himas-training:latest'
      - '-f'
      - 'PoC/Model-Pipeline/himas-model-pipeline/Dockerfile'
      - 'PoC/Model-Pipeline/himas-model-pipeline/'

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'train-model'
    env:
      - 'GCP_PROJECT_ID=$PROJECT_ID'
      - 'DATASET_ID=federated'
      - 'MLFLOW_TRACKING_URI=file:///workspace/mlruns'
      - 'MLFLOW_EXPERIMENT_NAME=himas-federated-training'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cp -r /workspace/PoC/Model-Pipeline/himas-model-pipeline/* /app/
        cd /app
        echo "Starting training with federated..."
        flwr run .
        mkdir -p /workspace/models
        
        # Find the model file wherever it was saved
        MODEL_FILE=$$(find models -name "*.keras" -type f | head -1)
        
        if [ -z "$$MODEL_FILE" ]; then
          echo "âŒ No model file found!"
          ls -lR models/
          exit 1
        fi
        
        echo "âœ… Found model: $$MODEL_FILE"
        cp $$MODEL_FILE /workspace/models/himas_federated_mortality_model.keras
        echo "âœ… Model copied to workspace:"
        ls -lh /workspace/models/

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'create-timestamp'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        TIMESTAMP=$$(date +%Y%m%d_%H%M%S)
        echo "$$TIMESTAMP" > /workspace/build_timestamp.txt
        echo "ðŸ“… Build timestamp: $$TIMESTAMP"

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'evaluate-model'
    env:
      - 'GCP_PROJECT_ID=$PROJECT_ID'
      - 'DATASET_ID=federated'
      - 'MLFLOW_TRACKING_URI=file:///workspace/mlruns'
      - 'MLFLOW_EXPERIMENT_NAME=himas-federated-eval'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cp -r /workspace/PoC/Model-Pipeline/himas-model-pipeline/* /app/
        cd /app
        mkdir -p models
        cp /workspace/models/himas_federated_mortality_model.keras models/

        cp -r /workspace/mlruns /app/ || echo "No mlruns from training"
        
        rm -rf evaluation_results
        mkdir -p evaluation_results
        python scripts/evaluate_model.py
        cp -r evaluation_results /workspace/

        cp -r /app/mlruns /workspace/ || echo "No mlruns folder found"

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'validate-metrics'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cd /workspace
        LATEST_JSON=$$(ls -t evaluation_results/results/*.json | head -1)
        echo "Using metrics from: $$LATEST_JSON"
        ACC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .accuracy' $$LATEST_JSON)
        REC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .recall' $$LATEST_JSON)
        echo "Accuracy: $$ACC | Recall: $$REC"
        if (( $$(echo "$$ACC < 0.85" | bc -l) )); then
          exit 1
        fi
        if (( $$(echo "$$REC < 0.60" | bc -l) )); then
          exit 1
        fi
        echo "Metrics passed"

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'bias-detection'
    env:
      - 'GCP_PROJECT_ID=$PROJECT_ID'
      - 'DATASET_ID=federated'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        set -e
        cp -r /workspace/PoC/Model-Pipeline/himas-model-pipeline/* /app/
        cd /app
        
        # Copy trained model
        mkdir -p models
        cp /workspace/models/himas_federated_mortality_model.keras models/
        
        echo "Running bias detection..."
        
        python bias_detection/detect_bias.py \
          --model-path models/himas_federated_mortality_model.keras \
          --threshold 0.5 \
          --dp-threshold 0.6 \
          --eo-threshold 1.1 \
          --output-dir bias_detection_results
      
        # Step 2: Check if bias passes threshold (CI/CD gate)
        python bias_detection/bias_checker.py \
          --bias-summary bias_detection_results/reports/bias_summary.json \
          --threshold-demographic-parity 0.6 \
          --threshold-equalized-odds 1.1
        
        echo "âœ… Bias detection complete"
        
        # Copy results to workspace for upload
        cp -r bias_detection_results /workspace/

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'compare-with-previous'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cd /workspace
        
        echo "Checking for previous model..."
        
        LATEST_JSON=$$(ls -t evaluation_results/results/*.json | head -1)
        NEW_ACC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .accuracy' $$LATEST_JSON)
        NEW_REC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .recall' $$LATEST_JSON)

        echo "New model - Accuracy: $$NEW_ACC, Recall: $$NEW_REC"
        
        # Get previous model timestamp from registry
        gsutil cp gs://himas-mlops-models/model-registry/latest.txt . || {
          echo "No previous model found. This is the first model - proceeding."
          exit 0
        }
        
        PREV_TIMESTAMP=$$(cat latest.txt)
        
        if [ -z "$$PREV_TIMESTAMP" ]; then
          echo "No previous model found. This is the first model - proceeding."
          exit 0
        fi
        
        echo "Found previous model: $$PREV_TIMESTAMP"
        
        # Download previous model's metrics
        mkdir -p prev_results
        gsutil cp -r gs://himas-mlops-models/evaluation-results/$$PREV_TIMESTAMP/evaluation_results/results/ prev_results/ || {
          echo "Could not fetch previous results. Proceeding with current model."
          exit 0
        }
        
        PREV_LATEST=$$(find prev_results -name "*.json" -type f | head -1)
        PREV_ACC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .accuracy' $$PREV_LATEST)
        PREV_REC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .recall' $$PREV_LATEST)
        
        echo "Previous model - Accuracy: $$PREV_ACC, Recall: $$PREV_REC"
        
        ACC_DIFF=$$(echo "$$NEW_ACC - $$PREV_ACC" | bc -l)
        REC_DIFF=$$(echo "$$NEW_REC - $$PREV_REC" | bc -l)
        
        echo "Accuracy difference: $$ACC_DIFF"
        echo "Recall difference: $$REC_DIFF"
        
        if (( $$(echo "$$ACC_DIFF < -0.02" | bc -l) )) || (( $$(echo "$$REC_DIFF < -0.02" | bc -l) )); then
          echo "âŒ ROLLBACK: New model performs worse than previous model"
          echo "   Previous: Acc=$$PREV_ACC, Rec=$$PREV_REC"
          echo "   New:      Acc=$$NEW_ACC, Rec=$$NEW_REC"
          exit 1
        else
          echo "âœ… New model is better or comparable. Proceeding with upload."
          exit 0
        fi

  - name: 'gcr.io/cloud-builders/gsutil'
    id: 'upload-model'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        TIMESTAMP=$$(cat /workspace/build_timestamp.txt)
        echo "Uploading model with timestamp: $$TIMESTAMP"
        gsutil cp /workspace/models/himas_federated_mortality_model.keras \
          gs://himas-mlops-models/models/$${TIMESTAMP}/model.keras

      
  - name: 'gcr.io/cloud-builders/gsutil'
    id: 'upload-results'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        TIMESTAMP=$$(cat /workspace/build_timestamp.txt)
        echo "Uploading results with timestamp: $$TIMESTAMP"
        gsutil -m cp -r /workspace/evaluation_results/ \
          gs://himas-mlops-models/evaluation-results/$${TIMESTAMP}/
        echo "UPLOAD STEP TIMESTAMP: $(cat /workspace/build_timestamp.txt)"

  - name: 'gcr.io/cloud-builders/gsutil'
    id: 'upload-mlflow-artifacts'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        TIMESTAMP=$$(cat /workspace/build_timestamp.txt)
        echo "Uploading MLflow artifacts with timestamp: $$TIMESTAMP"
        gsutil -m cp -r /workspace/mlruns \
          gs://himas-mlops-models/mlflow-runs/$${TIMESTAMP}/

  - name: 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
    id: 'register-model-in-registry'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cd /workspace
        
        # Read timestamp
        TIMESTAMP=$$(cat /workspace/build_timestamp.txt)
        echo "Using timestamp: $$TIMESTAMP"

        # Get metrics
        LATEST_JSON=$$(ls -t evaluation_results/results/*.json | head -1)
        ACC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .accuracy' $$LATEST_JSON)
        REC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .recall' $$LATEST_JSON)
        PREC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .precision' $$LATEST_JSON)
        F1=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .f1_score' $$LATEST_JSON)
        AUC=$$(jq '.metrics_by_hospital[] | select(.hospital=="AGGREGATED") | .roc_auc' $$LATEST_JSON)
        
        echo "Registering model in Model Registry..."
        echo "Metrics - Accuracy: $$ACC | Recall: $$REC | Precision: $$PREC"
        
        # Create model registry entry (model card)
        cat > model_card.json <<EOF
        {
          "model_info": {
            "name": "himas-federated-mortality-model",
            "version": "$BUILD_ID",
            "timestamp": "$$TIMESTAMP",
            "status": "production",
            "registered_at": "$$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          },
          "artifacts": {
            "model_file": "gs://himas-mlops-models/models/$${TIMESTAMP}/model.keras",
            "evaluation_results": "gs://himas-mlops-models/evaluation-results/$${TIMESTAMP}/",
            "mlflow_tracking": "gs://himas-mlops-models/mlflow-runs/$${TIMESTAMP}/"
          },
          "performance_metrics": {
            "accuracy": $$ACC,
            "recall": $$REC,
            "precision": $$PREC,
            "f1_score": $$F1,
            "roc_auc": $$AUC
          },
          "training_config": {
            "framework": "tensorflow-keras",
            "federated_framework": "flower",
            "hospitals": ["hospital_a", "hospital_b", "hospital_c"],
            "num_rounds": 15,
            "local_epochs": 5,
            "batch_size": 64
          }
        }
        EOF
        
        echo ""
        echo "Model Registry Entry:"
        cat model_card.json
        echo ""
        
        # Upload to model registry in GCS
        gsutil cp model_card.json \
          gs://himas-mlops-models/model-registry/$${TIMESTAMP}.json
        
        # Update latest pointer
        echo "$$TIMESTAMP" > latest_model.txt
        gsutil cp latest_model.txt gs://himas-mlops-models/model-registry/latest.txt
        
        echo ""
        echo "âœ… Model registered in Model Registry (GCS-based)"
        echo "   Registry Entry: gs://himas-mlops-models/model-registry/$${TIMESTAMP}.json"
        echo "   Model Artifact: gs://himas-mlops-models/models/$${TIMESTAMP}/model.keras"
        echo "   Container Image: gcr.io/$PROJECT_ID/himas-training:$BUILD_ID"
        echo "   Latest Model: gs://himas-mlops-models/model-registry/latest.txt"

  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'vertex-ai-register'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ðŸ“Œ Registering model in Vertex AI Model Registry..."

        PROJECT_ID=${PROJECT_ID}
        REGION=us-central1

        # Use double-dollar to avoid Cloud Build substitution parsing
        TIMESTAMP=$$(cat /workspace/build_timestamp.txt)

        MODEL_PATH="gs://himas-mlops-models/models/$${TIMESTAMP}/"

        echo "Model artifact: $${MODEL_PATH}"

        MODEL_ID=$$(gcloud ai models upload \
          --region=$${REGION} \
          --display-name="himas-federated-mortality-model" \
          --artifact-uri="$${MODEL_PATH}" \
          --container-image-uri="gcr.io/$${PROJECT_ID}/himas-training:latest" \
          --format="value(name)")

        echo "Vertex Model ID: $${MODEL_ID}"
        echo "$${MODEL_ID}" > /workspace/vertex_model_id.txt
        echo "VERTEX STEP TIMESTAMP: $(cat /workspace/build_timestamp.txt)"



images:
  - 'gcr.io/$PROJECT_ID/himas-training:$BUILD_ID'
  - 'gcr.io/$PROJECT_ID/himas-training:latest'

options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY

timeout: '3600s'